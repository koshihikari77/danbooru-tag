# Danbooru Tag Hierarchy Scraper 開発経緯

## プロジェクト概要

DanbooruのTag Groupsとタグの階層構造をスクレイピングし、親子関係データベースを構築するプロジェクト。

### 開発目的
- tag group, tagの親子関係の抽出
- tagから親のパスの特定
- tag groupから属しているtagの一覧取得
- 人物特徴（目の色、髪の色等）の識別・分離による画像編集支援

## 開発フェーズと技術的進化

### Phase 1: 初期調査・概念実証 (2024年6月)
- **目標**: Danbooruからのデータ取得可能性検証
- **手法**: API調査、WebFetch検証
- **成果**: ハイブリッド手法（API + WebFetch）の確立
- **主要発見**: 
  - DanbooruのAPIはwiki page階層構造を提供しない
  - WebFetchによるHTMLパース手法が最適
  - tag groupページから階層構造取得が可能

### Phase 2: スクレイパー実装 (2024年6月)
- **統合階層スクレイパー**の開発
- BeautifulSoupによるHTML構造解析
- 基本的な親子関係抽出機能
- レート制限対応（1秒間隔）

### Phase 3: スケーラブル設計への移行 (2024年6月下旬)
- **課題**: 全tag groups対応の必要性
- **解決**: `scalable_hierarchy_scraper.py` 開発
- **特徴**:
  - Copyrights, artists, projects and media除外対応
  - 4-way分類システム実装
  - target_groups指定によるフィルタリング機能

### Phase 4: 品質向上・バグ修正 (2024年6月29日)
- **重要なバグ修正**:
  1. **Large areolae階層問題**: 中間親（areolae）の欠如修正
  2. **Animal ears問題**: Body parts詳細データ取得不備修正
  3. **統合処理問題**: breasts + tag group:breasts tags → breasts 統合実装

## 技術的成果

### 4-way分類システム
```python
TAG_AND_TAG_GROUP    # リンク有 + ネストリスト有 + 'tag group'なし
FINAL_TAG_ONLY       # リンクなし + ネストリストなし
TAG_GROUP_ONLY       # リンクなし + ネストリスト有
TRADITIONAL_TAG_GROUP # 'tag group'を名前に含む
```

### 階層構造処理
- **兄弟ul処理**: `<li><a>parent</a></li><ul><li>child</li></ul>` パターン対応
- **ネストul処理**: `<li><a>parent</a><ul><li>child</li></ul></li>` パターン対応
- **重複除去**: 処理済みマーキングによる重複処理防止

### 統合処理
- `tag group:X tags` → `X` の自動統合
- 冗長なタググループペアの削除
- 統合前後の詳細ログ出力

## 最終仕様

### 処理能力
- **分類項目数**: 2,141項目
- **統合処理**: 9件の冗長項目統合
- **重複除去**: 75件の重複除去
- **正規化**: 970件の大文字小文字正規化

### 品質保証
- **階層構造検証**: 完全なパス構造確認
- **テストケース**: 8/8項目パス（100%）
- **コンプライアンス**: EXCELLENT評価

### パフォーマンス
- **レート制限**: 0.5秒間隔（サーバー負荷軽減）
- **並列処理**: curlを使用した効率的な取得
- **メモリ効率**: 段階的処理による省メモリ実装

## 技術的挑戦と解決

### 1. Large areolae階層問題
**問題**: `areolae -> large areolae` の中間親が欠如
**原因**: 兄弟ul処理時の重複処理ロジック
**解決**: 兄弟ul内li要素の処理順序修正、マーキング戦略改善

### 2. 統合処理のマッチング問題
**問題**: `tag group:breasts tags` → `breasts` のマッチング失敗
**原因**: "X tags" → "X" 変換ロジックの不備
**解決**: 複数マッチングオプション実装、柔軟なマッチング戦略

### 3. Target groups使用時のリンク追跡問題
**問題**: フィルタリング後のリンク追跡不備
**原因**: should_process_group メソッドの過度なフィルタリング
**解決**: フィルタリングロジックの改善、詳細ページ取得の確実化

## 開発手法の特徴

### TDD (Test-Driven Development)
- t-wadaのTDD手法を参考
- 実際のデータとの比較検証
- 継続的な品質改善

### 段階的開発
1. **検証フェーズ**: データ取得可能性確認
2. **実装フェーズ**: 機能開発
3. **修正フェーズ**: バグ修正・品質向上
4. **統合フェーズ**: 最終統合・文書化

### ログ駆動開発
- logger使用による詳細なトレーサビリティ
- 段階的デバッグ情報出力
- パフォーマンス測定

## プロジェクト成果物

### メインスクリプト
- `scalable_hierarchy_scraper.py`: 本体スクレイパー（1,004行）
- 完全な階層構造抽出機能
- 4-way分類システム
- 統合・正規化処理

### 検証システム
- `detailed_validation_report.py`: 包括的検証スクリプト
- 8項目の詳細テストケース
- 自動品質評価システム

### データ成果物
- 2,141項目の分類済みタグデータ
- 完全な階層パス情報
- 統合済み冗長項目処理

## 技術的レガシー

このプロジェクトにより確立された技術：

1. **スケーラブルWebスクレイピング**: 大規模サイトからの段階的データ取得
2. **階層構造解析**: 複雑なHTML構造からの親子関係抽出
3. **データ品質保証**: 実データ比較による検証手法
4. **統合処理パターン**: 冗長データの自動統合

この経験により、類似の階層構造スクレイピングプロジェクトに対する再利用可能な技術基盤が構築された。